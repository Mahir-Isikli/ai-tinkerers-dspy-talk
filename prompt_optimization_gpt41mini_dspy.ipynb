{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "712aea9f",
   "metadata": {},
   "source": [
    "# Automatic System Prompt Optimization (DSPy) â€” with **gpt-4.1-mini**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df7f901",
   "metadata": {},
   "source": [
    "This notebook uses DSPy to optimize a *system prompt* for a task, targeting OpenAI's **gpt-4.1-mini**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0214b0e6",
   "metadata": {},
   "source": [
    "## 1) Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9eadc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%pip install -U dspy openai tiktoken\n",
    "\n",
    "import os, re\n",
    "import dspy\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "BASE_MODEL = \"openai/gpt-4.1-mini\"\n",
    "JUDGE_MODEL = \"openai/gpt-4.1\"\n",
    "\n",
    "dspy.configure(lm=dspy.LM(BASE_MODEL))\n",
    "print(\"DSPy:\", dspy.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0962df86",
   "metadata": {},
   "source": [
    "## 2) Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a909ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import dspy\n",
    "train_examples = [\n",
    "    dspy.Example(prompt=\"What is the capital of France?\", generation=\"Paris.\"),\n",
    "    dspy.Example(prompt=\"Who wrote '1984'?\", generation=\"George Orwell.\"),\n",
    "]\n",
    "dev_examples = [dspy.Example(prompt=\"What is the largest planet?\", generation=\"Jupiter.\")]\n",
    "\n",
    "trainset = [e.with_inputs(\"prompt\") for e in train_examples]\n",
    "devset   = [e.with_inputs(\"prompt\") for e in dev_examples]\n",
    "(len(trainset), len(devset))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3dc4b9b",
   "metadata": {},
   "source": [
    "## 3) Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c508c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def token_f1(pred, ref):\n",
    "    p = pred.lower().split(); r = ref.lower().split()\n",
    "    if not p or not r: return 0.0\n",
    "    from collections import Counter\n",
    "    cp, cr = Counter(p), Counter(r)\n",
    "    overlap = sum((cp & cr).values())\n",
    "    prec = overlap/len(p); rec = overlap/len(r)\n",
    "    return 0.0 if (prec+rec)==0 else 2*prec*rec/(prec+rec)\n",
    "\n",
    "def concise_qna_metric(example, prediction, trace=None):\n",
    "    out = (prediction.get(\"generation\") or \"\").strip()\n",
    "    ref = (example.get(\"generation\") or \"\").strip()\n",
    "    if not out: return 0.0\n",
    "    # Encourage <= 2 sentences\n",
    "    import re as _re\n",
    "    sentences = [s for s in _re.split(r\"[.!?]+\", out) if s.strip()]\n",
    "    length_pen = 0.0 if len(sentences)<=2 else min(1.0, 0.2*(len(sentences)-2))\n",
    "    return max(0.0, min(1.0, token_f1(out, ref)-length_pen))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41616441",
   "metadata": {},
   "source": [
    "## 4) Minimal program with custom adapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ca493f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class signature(dspy.Signature):\n",
    "    prompt = dspy.InputField()\n",
    "    generation = dspy.OutputField()\n",
    "\n",
    "def format_demos(demos):\n",
    "    s = []\n",
    "    for d in (demos or []):\n",
    "        s.append(f\"\\n# Example\\nUser: {d.inputs.get('prompt','')}\\nAssistant: {d.outputs.get('generation','')}\")\n",
    "    return \"\\n\".join(s)\n",
    "\n",
    "class SimplestAdapter(dspy.Adapter):\n",
    "    def __call__(self, lm, lm_kwargs, signature, demos, inputs):\n",
    "        sys_msg = signature.instructions or \"\"\n",
    "        if demos: sys_msg += \"\\n\" + format_demos(demos)\n",
    "        messages = [\n",
    "            {\"role\":\"system\",\"content\": sys_msg},\n",
    "            {\"role\":\"user\",\"content\": inputs[\"prompt\"]},\n",
    "        ]\n",
    "        outputs = lm(messages=messages, **lm_kwargs)\n",
    "        return [{\"generation\": outputs[0]}]\n",
    "\n",
    "class MyPredict(dspy.Predict):\n",
    "    def __init__(self, signature, **kw):\n",
    "        super().__init__(signature, **kw)\n",
    "        self.adapter = SimplestAdapter()\n",
    "\n",
    "INITIAL_SYSTEM_PROMPT = \"You are concise. Answer correctly in <= 2 sentences.\"\n",
    "my_program = MyPredict(signature)\n",
    "my_program.signature.instructions = INITIAL_SYSTEM_PROMPT\n",
    "print(my_program(prompt=\"Who painted the Mona Lisa?\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b84a72c",
   "metadata": {},
   "source": [
    "## 5) Optimize (MIPROv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c319826",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "optimizer = dspy.MIPROv2(concise_qna_metric, max_bootstrapped_demos=0, max_labeled_demos=0)\n",
    "my_program_optimized = optimizer.compile(my_program, trainset=trainset, requires_permission_to_run=False)\n",
    "print(my_program_optimized(prompt=\"What is the capital of Germany?\"))\n",
    "my_program_optimized.inspect_history()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35faed0",
   "metadata": {},
   "source": [
    "## 6) Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77bea211",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(program, dataset, metric):\n",
    "    scores = []\n",
    "    for ex in dataset:\n",
    "        # pull input & reference safely from dspy.Example\n",
    "        user_prompt = getattr(ex, \"prompt\", None) or getattr(ex, \"inputs\", {}).get(\"prompt\", \"\")\n",
    "        ref_answer  = getattr(ex, \"generation\", None) or getattr(ex, \"outputs\", {}).get(\"generation\", \"\")\n",
    "\n",
    "        # run program\n",
    "        pred = program(prompt=user_prompt)\n",
    "\n",
    "        # normalize prediction to a dict with \"generation\"\n",
    "        gen = getattr(pred, \"generation\", None)\n",
    "        if gen is None and hasattr(pred, \"as_dict\"):\n",
    "            gen = pred.as_dict().get(\"generation\", \"\")\n",
    "        if gen is None and hasattr(pred, \"toDict\"):\n",
    "            gen = pred.toDict().get(\"generation\", \"\")\n",
    "        if gen is None and hasattr(pred, \"outputs\") and isinstance(pred.outputs, dict):\n",
    "            gen = pred.outputs.get(\"generation\", \"\")\n",
    "        if gen is None:\n",
    "            try:\n",
    "                gen = pred[\"generation\"]  # last resort if subscriptable\n",
    "            except Exception:\n",
    "                gen = str(pred)\n",
    "\n",
    "        ex_dict   = {\"prompt\": user_prompt, \"generation\": ref_answer}\n",
    "        pred_dict = {\"generation\": gen}\n",
    "        scores.append(metric(ex_dict, pred_dict))\n",
    "\n",
    "    return sum(scores) / len(scores) if scores else 0.0\n",
    "\n",
    "base = evaluate(my_program, devset, concise_qna_metric)\n",
    "opt  = evaluate(my_program_optimized, devset, concise_qna_metric)\n",
    "print(\"Base:\", base, \"Optimized:\", opt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6f5f4a",
   "metadata": {},
   "source": [
    "## 7) Export learned system prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8263f77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "final_instructions = my_program_optimized.signature.instructions\n",
    "with open(\"optimized_system_prompt.txt\",\"w\",encoding=\"utf-8\") as f:\n",
    "    f.write(final_instructions)\n",
    "print(final_instructions)\n",
    "print(\"\\nSaved to optimized_system_prompt.txt\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
