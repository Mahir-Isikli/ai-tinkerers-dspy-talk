{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "712aea9f",
   "metadata": {},
   "source": [
    "# Automatic System Prompt Optimization (DSPy) â€” with **gpt-4.1-mini**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df7f901",
   "metadata": {},
   "source": [
    "This notebook uses DSPy to optimize a *system prompt* for a task, targeting OpenAI's **gpt-4.1-mini**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0214b0e6",
   "metadata": {},
   "source": [
    "## 1) Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9eadc7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: dspy in /opt/homebrew/lib/python3.11/site-packages (2.6.27)\n",
      "Requirement already satisfied: openai in /opt/homebrew/lib/python3.11/site-packages (1.99.6)\n",
      "Requirement already satisfied: tiktoken in /opt/homebrew/lib/python3.11/site-packages (0.11.0)\n",
      "Requirement already satisfied: backoff>=2.2 in /opt/homebrew/lib/python3.11/site-packages (from dspy) (2.2.1)\n",
      "Requirement already satisfied: joblib~=1.3 in /opt/homebrew/lib/python3.11/site-packages (from dspy) (1.5.1)\n",
      "Requirement already satisfied: pandas>=2.1.1 in /opt/homebrew/lib/python3.11/site-packages (from dspy) (2.3.1)\n",
      "Requirement already satisfied: regex>=2023.10.3 in /opt/homebrew/lib/python3.11/site-packages (from dspy) (2025.7.34)\n",
      "Requirement already satisfied: ujson>=5.8.0 in /opt/homebrew/lib/python3.11/site-packages (from dspy) (5.10.0)\n",
      "Requirement already satisfied: tqdm>=4.66.1 in /opt/homebrew/lib/python3.11/site-packages (from dspy) (4.67.1)\n",
      "Requirement already satisfied: datasets>=2.14.6 in /opt/homebrew/lib/python3.11/site-packages (from dspy) (4.0.0)\n",
      "Requirement already satisfied: requests>=2.31.0 in /opt/homebrew/lib/python3.11/site-packages (from dspy) (2.32.4)\n",
      "Requirement already satisfied: optuna>=3.4.0 in /opt/homebrew/lib/python3.11/site-packages (from dspy) (4.4.0)\n",
      "Requirement already satisfied: pydantic>=2.0 in /opt/homebrew/lib/python3.11/site-packages (from dspy) (2.11.7)\n",
      "Requirement already satisfied: magicattr>=0.1.6 in /opt/homebrew/lib/python3.11/site-packages (from dspy) (0.1.6)\n",
      "Requirement already satisfied: litellm>=1.60.3 in /opt/homebrew/lib/python3.11/site-packages (from dspy) (1.75.4)\n",
      "Requirement already satisfied: diskcache>=5.6.0 in /opt/homebrew/lib/python3.11/site-packages (from dspy) (5.6.3)\n",
      "Requirement already satisfied: json-repair>=0.30.0 in /opt/homebrew/lib/python3.11/site-packages (from dspy) (0.49.0)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in /opt/homebrew/lib/python3.11/site-packages (from dspy) (9.1.2)\n",
      "Requirement already satisfied: anyio in /opt/homebrew/lib/python3.11/site-packages (from dspy) (4.10.0)\n",
      "Requirement already satisfied: asyncer==0.0.8 in /opt/homebrew/lib/python3.11/site-packages (from dspy) (0.0.8)\n",
      "Requirement already satisfied: cachetools>=5.5.0 in /opt/homebrew/lib/python3.11/site-packages (from dspy) (6.1.0)\n",
      "Requirement already satisfied: cloudpickle>=3.0.0 in /opt/homebrew/lib/python3.11/site-packages (from dspy) (3.1.1)\n",
      "Requirement already satisfied: rich>=13.7.1 in /opt/homebrew/lib/python3.11/site-packages (from dspy) (14.1.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /opt/homebrew/lib/python3.11/site-packages (from dspy) (2.3.2)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/homebrew/lib/python3.11/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/homebrew/lib/python3.11/site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /opt/homebrew/lib/python3.11/site-packages (from openai) (0.10.0)\n",
      "Requirement already satisfied: sniffio in /opt/homebrew/lib/python3.11/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /Users/mahirisikli/Library/Python/3.11/lib/python/site-packages (from openai) (4.14.1)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/homebrew/lib/python3.11/site-packages (from anyio->dspy) (3.10)\n",
      "Requirement already satisfied: filelock in /opt/homebrew/lib/python3.11/site-packages (from datasets>=2.14.6->dspy) (3.18.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/homebrew/lib/python3.11/site-packages (from datasets>=2.14.6->dspy) (21.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/homebrew/lib/python3.11/site-packages (from datasets>=2.14.6->dspy) (0.3.8)\n",
      "Requirement already satisfied: xxhash in /opt/homebrew/lib/python3.11/site-packages (from datasets>=2.14.6->dspy) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /opt/homebrew/lib/python3.11/site-packages (from datasets>=2.14.6->dspy) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /opt/homebrew/lib/python3.11/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.14.6->dspy) (2025.3.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /opt/homebrew/lib/python3.11/site-packages (from datasets>=2.14.6->dspy) (0.34.4)\n",
      "Requirement already satisfied: packaging in /Users/mahirisikli/Library/Python/3.11/lib/python/site-packages (from datasets>=2.14.6->dspy) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/homebrew/lib/python3.11/site-packages (from datasets>=2.14.6->dspy) (6.0.2)\n",
      "Requirement already satisfied: certifi in /opt/homebrew/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/homebrew/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/homebrew/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: aiohttp>=3.10 in /opt/homebrew/lib/python3.11/site-packages (from litellm>=1.60.3->dspy) (3.12.15)\n",
      "Requirement already satisfied: click in /opt/homebrew/lib/python3.11/site-packages (from litellm>=1.60.3->dspy) (8.2.1)\n",
      "Requirement already satisfied: importlib-metadata>=6.8.0 in /opt/homebrew/lib/python3.11/site-packages (from litellm>=1.60.3->dspy) (8.7.0)\n",
      "Requirement already satisfied: jinja2<4.0.0,>=3.1.2 in /opt/homebrew/lib/python3.11/site-packages (from litellm>=1.60.3->dspy) (3.1.6)\n",
      "Requirement already satisfied: jsonschema<5.0.0,>=4.22.0 in /opt/homebrew/lib/python3.11/site-packages (from litellm>=1.60.3->dspy) (4.25.0)\n",
      "Requirement already satisfied: python-dotenv>=0.2.0 in /opt/homebrew/lib/python3.11/site-packages (from litellm>=1.60.3->dspy) (1.1.1)\n",
      "Requirement already satisfied: tokenizers in /opt/homebrew/lib/python3.11/site-packages (from litellm>=1.60.3->dspy) (0.21.4)\n",
      "Requirement already satisfied: alembic>=1.5.0 in /opt/homebrew/lib/python3.11/site-packages (from optuna>=3.4.0->dspy) (1.16.4)\n",
      "Requirement already satisfied: colorlog in /opt/homebrew/lib/python3.11/site-packages (from optuna>=3.4.0->dspy) (6.9.0)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in /opt/homebrew/lib/python3.11/site-packages (from optuna>=3.4.0->dspy) (2.0.42)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/mahirisikli/Library/Python/3.11/lib/python/site-packages (from pandas>=2.1.1->dspy) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/homebrew/lib/python3.11/site-packages (from pandas>=2.1.1->dspy) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/homebrew/lib/python3.11/site-packages (from pandas>=2.1.1->dspy) (2025.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/homebrew/lib/python3.11/site-packages (from pydantic>=2.0->dspy) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /opt/homebrew/lib/python3.11/site-packages (from pydantic>=2.0->dspy) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /opt/homebrew/lib/python3.11/site-packages (from pydantic>=2.0->dspy) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/homebrew/lib/python3.11/site-packages (from requests>=2.31.0->dspy) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/lib/python3.11/site-packages (from requests>=2.31.0->dspy) (2.5.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/homebrew/lib/python3.11/site-packages (from rich>=13.7.1->dspy) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/mahirisikli/Library/Python/3.11/lib/python/site-packages (from rich>=13.7.1->dspy) (2.19.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp>=3.10->litellm>=1.60.3->dspy) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp>=3.10->litellm>=1.60.3->dspy) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp>=3.10->litellm>=1.60.3->dspy) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp>=3.10->litellm>=1.60.3->dspy) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp>=3.10->litellm>=1.60.3->dspy) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp>=3.10->litellm>=1.60.3->dspy) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp>=3.10->litellm>=1.60.3->dspy) (1.20.1)\n",
      "Requirement already satisfied: Mako in /opt/homebrew/lib/python3.11/site-packages (from alembic>=1.5.0->optuna>=3.4.0->dspy) (1.3.10)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /opt/homebrew/lib/python3.11/site-packages (from huggingface-hub>=0.24.0->datasets>=2.14.6->dspy) (1.1.7)\n",
      "Requirement already satisfied: zipp>=3.20 in /opt/homebrew/lib/python3.11/site-packages (from importlib-metadata>=6.8.0->litellm>=1.60.3->dspy) (3.23.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/homebrew/lib/python3.11/site-packages (from jinja2<4.0.0,>=3.1.2->litellm>=1.60.3->dspy) (3.0.2)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/homebrew/lib/python3.11/site-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.60.3->dspy) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/homebrew/lib/python3.11/site-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.60.3->dspy) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/homebrew/lib/python3.11/site-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.60.3->dspy) (0.27.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/homebrew/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich>=13.7.1->dspy) (0.1.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/mahirisikli/Library/Python/3.11/lib/python/site-packages (from python-dateutil>=2.8.2->pandas>=2.1.1->dspy) (1.17.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "DSPy: 2.6.27\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%pip install -U dspy openai tiktoken\n",
    "\n",
    "import os, re\n",
    "import dspy\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "BASE_MODEL = \"openai/gpt-4.1-mini\"\n",
    "JUDGE_MODEL = \"openai/gpt-4.1\"\n",
    "\n",
    "dspy.configure(lm=dspy.LM(BASE_MODEL))\n",
    "print(\"DSPy:\", dspy.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0962df86",
   "metadata": {},
   "source": [
    "## 2) Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46a909ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import dspy\n",
    "train_examples = [\n",
    "    dspy.Example(prompt=\"What is the capital of France?\", generation=\"Paris.\"),\n",
    "    dspy.Example(prompt=\"Who wrote '1984'?\", generation=\"George Orwell.\"),\n",
    "]\n",
    "dev_examples = [dspy.Example(prompt=\"What is the largest planet?\", generation=\"Jupiter.\")]\n",
    "\n",
    "trainset = [e.with_inputs(\"prompt\") for e in train_examples]\n",
    "devset   = [e.with_inputs(\"prompt\") for e in dev_examples]\n",
    "(len(trainset), len(devset))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3dc4b9b",
   "metadata": {},
   "source": [
    "## 3) Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c508c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def token_f1(pred, ref):\n",
    "    p = pred.lower().split(); r = ref.lower().split()\n",
    "    if not p or not r: return 0.0\n",
    "    from collections import Counter\n",
    "    cp, cr = Counter(p), Counter(r)\n",
    "    overlap = sum((cp & cr).values())\n",
    "    prec = overlap/len(p); rec = overlap/len(r)\n",
    "    return 0.0 if (prec+rec)==0 else 2*prec*rec/(prec+rec)\n",
    "\n",
    "def concise_qna_metric(example, prediction, trace=None):\n",
    "    out = (prediction.get(\"generation\") or \"\").strip()\n",
    "    ref = (example.get(\"generation\") or \"\").strip()\n",
    "    if not out: return 0.0\n",
    "    # Encourage <= 2 sentences\n",
    "    import re as _re\n",
    "    sentences = [s for s in _re.split(r\"[.!?]+\", out) if s.strip()]\n",
    "    length_pen = 0.0 if len(sentences)<=2 else min(1.0, 0.2*(len(sentences)-2))\n",
    "    return max(0.0, min(1.0, token_f1(out, ref)-length_pen))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41616441",
   "metadata": {},
   "source": [
    "## 4) Minimal program with custom adapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4ca493f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction(\n",
      "    generation='The Mona Lisa was painted by Leonardo da Vinci.'\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class signature(dspy.Signature):\n",
    "    prompt = dspy.InputField()\n",
    "    generation = dspy.OutputField()\n",
    "\n",
    "def format_demos(demos):\n",
    "    s = []\n",
    "    for d in (demos or []):\n",
    "        s.append(f\"\\n# Example\\nUser: {d.inputs.get('prompt','')}\\nAssistant: {d.outputs.get('generation','')}\")\n",
    "    return \"\\n\".join(s)\n",
    "\n",
    "class SimplestAdapter(dspy.Adapter):\n",
    "    def __call__(self, lm, lm_kwargs, signature, demos, inputs):\n",
    "        sys_msg = signature.instructions or \"\"\n",
    "        if demos: sys_msg += \"\\n\" + format_demos(demos)\n",
    "        messages = [\n",
    "            {\"role\":\"system\",\"content\": sys_msg},\n",
    "            {\"role\":\"user\",\"content\": inputs[\"prompt\"]},\n",
    "        ]\n",
    "        outputs = lm(messages=messages, **lm_kwargs)\n",
    "        return [{\"generation\": outputs[0]}]\n",
    "\n",
    "class MyPredict(dspy.Predict):\n",
    "    def __init__(self, signature, **kw):\n",
    "        super().__init__(signature, **kw)\n",
    "        self.adapter = SimplestAdapter()\n",
    "\n",
    "INITIAL_SYSTEM_PROMPT = \"You are concise. Answer correctly in <= 2 sentences.\"\n",
    "my_program = MyPredict(signature)\n",
    "my_program.signature.instructions = INITIAL_SYSTEM_PROMPT\n",
    "print(my_program(prompt=\"Who painted the Mona Lisa?\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b84a72c",
   "metadata": {},
   "source": [
    "## 5) Optimize (MIPROv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c319826",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/10 16:27:49 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "RUNNING WITH THE FOLLOWING LIGHT AUTO RUN SETTINGS:\n",
      "num_trials: 9\n",
      "minibatch: False\n",
      "num_fewshot_candidates: 6\n",
      "num_instruct_candidates: 6\n",
      "valset size: 1\n",
      "\n",
      "2025/08/10 16:27:49 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "==> STEP 1: BOOTSTRAP FEWSHOT EXAMPLES <==\n",
      "2025/08/10 16:27:49 INFO dspy.teleprompt.mipro_optimizer_v2: These will be used for informing instruction proposal.\n",
      "\n",
      "2025/08/10 16:27:49 INFO dspy.teleprompt.mipro_optimizer_v2: Bootstrapping N=6 sets of demonstrations...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapping set 1/6\n",
      "Bootstrapping set 2/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 0 examples for up to 1 rounds, amounting to 1 attempts.\n",
      "Bootstrapping set 3/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 1709.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 0 examples for up to 1 rounds, amounting to 1 attempts.\n",
      "Bootstrapping set 4/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 2525.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 0 examples for up to 1 rounds, amounting to 1 attempts.\n",
      "Bootstrapping set 5/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 2398.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 0 examples for up to 1 rounds, amounting to 1 attempts.\n",
      "Bootstrapping set 6/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 2732.45it/s]\n",
      "2025/08/10 16:27:50 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "==> STEP 2: PROPOSE INSTRUCTION CANDIDATES <==\n",
      "2025/08/10 16:27:50 INFO dspy.teleprompt.mipro_optimizer_v2: We will use the few-shot examples from the previous step, a generated dataset summary, a summary of the program code, and a randomly selected prompting tip to propose instructions.\n",
      "2025/08/10 16:27:50 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "Proposing N=6 instructions...\n",
      "\n",
      "2025/08/10 16:27:50 INFO dspy.teleprompt.mipro_optimizer_v2: Proposed Instructions for Predictor 0:\n",
      "\n",
      "2025/08/10 16:27:50 INFO dspy.teleprompt.mipro_optimizer_v2: 0: You are concise. Answer correctly in <= 2 sentences.\n",
      "\n",
      "2025/08/10 16:27:50 INFO dspy.teleprompt.mipro_optimizer_v2: 1: Answer the following factual question accurately and concisely. Provide a direct response in one or two sentences without unnecessary elaboration.\n",
      "\n",
      "2025/08/10 16:27:50 INFO dspy.teleprompt.mipro_optimizer_v2: 2: Answer the given factual question accurately and concisely, providing a direct and precise response. Keep your answer to one or two sentences, focusing on delivering clear, specific information without additional commentary or elaboration.\n",
      "\n",
      "2025/08/10 16:27:50 INFO dspy.teleprompt.mipro_optimizer_v2: 3: Answer the factual question accurately and concisely, using no more than two sentences. Provide a direct response that clearly addresses the question without unnecessary elaboration.\n",
      "\n",
      "2025/08/10 16:27:50 INFO dspy.teleprompt.mipro_optimizer_v2: 4: You are a trusted expert providing critical information in a high-stakes emergency scenario where accuracy and brevity save lives. Answer the factual question correctly and concisely in no more than two sentences.\n",
      "\n",
      "2025/08/10 16:27:50 INFO dspy.teleprompt.mipro_optimizer_v2: 5: You are a knowledgeable and concise general knowledge expert. Provide accurate, fact-based answers to straightforward questions in one or two sentences, ensuring clarity and precision.\n",
      "\n",
      "2025/08/10 16:27:50 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "\n",
      "2025/08/10 16:27:50 INFO dspy.teleprompt.mipro_optimizer_v2: ==> STEP 3: FINDING OPTIMAL PROMPT PARAMETERS <==\n",
      "2025/08/10 16:27:50 INFO dspy.teleprompt.mipro_optimizer_v2: We will evaluate the program over a series of trials with different combinations of instructions and few-shot examples to find the optimal combination using Bayesian Optimization.\n",
      "\n",
      "2025/08/10 16:27:50 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 1 / 9 - Full Evaluation of Default Program ==\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 0 examples for up to 1 rounds, amounting to 1 attempts.\n",
      "Error getting source code: unhashable type: 'dict'.\n",
      "\n",
      "Running without program aware proposer.\n",
      "Average Metric: 0.20 / 1 (20.0%): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 874.91it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/10 16:27:50 INFO dspy.evaluate.evaluate: Average Metric: 0.2 / 1 (20.0%)\n",
      "2025/08/10 16:27:50 INFO dspy.teleprompt.mipro_optimizer_v2: Default program score: 20.0\n",
      "\n",
      "/opt/homebrew/lib/python3.11/site-packages/optuna/_experimental.py:32: ExperimentalWarning: Argument ``multivariate`` is an experimental feature. The interface can change in the future.\n",
      "  warnings.warn(\n",
      "2025/08/10 16:27:50 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 2 / 9 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 0.33 / 1 (33.3%): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 1631.39it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/10 16:27:50 INFO dspy.evaluate.evaluate: Average Metric: 0.3333333333333333 / 1 (33.3%)\n",
      "2025/08/10 16:27:50 INFO dspy.teleprompt.mipro_optimizer_v2: \u001b[92mBest full score so far!\u001b[0m Score: 33.33\n",
      "2025/08/10 16:27:50 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 33.33 with parameters ['Predictor 0: Instruction 1'].\n",
      "2025/08/10 16:27:50 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [20.0, 33.33]\n",
      "2025/08/10 16:27:50 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 33.33\n",
      "2025/08/10 16:27:50 INFO dspy.teleprompt.mipro_optimizer_v2: =======================\n",
      "\n",
      "\n",
      "2025/08/10 16:27:50 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 3 / 9 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 0.50 / 1 (50.0%): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 2012.62it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/10 16:27:50 INFO dspy.evaluate.evaluate: Average Metric: 0.5 / 1 (50.0%)\n",
      "2025/08/10 16:27:50 INFO dspy.teleprompt.mipro_optimizer_v2: \u001b[92mBest full score so far!\u001b[0m Score: 50.0\n",
      "2025/08/10 16:27:50 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 50.0 with parameters ['Predictor 0: Instruction 5'].\n",
      "2025/08/10 16:27:50 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [20.0, 33.33, 50.0]\n",
      "2025/08/10 16:27:50 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 50.0\n",
      "2025/08/10 16:27:50 INFO dspy.teleprompt.mipro_optimizer_v2: =======================\n",
      "\n",
      "\n",
      "2025/08/10 16:27:50 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 4 / 9 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 0.20 / 1 (20.0%): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 4064.25it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/10 16:27:50 INFO dspy.evaluate.evaluate: Average Metric: 0.2 / 1 (20.0%)\n",
      "2025/08/10 16:27:50 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 20.0 with parameters ['Predictor 0: Instruction 0'].\n",
      "2025/08/10 16:27:50 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [20.0, 33.33, 50.0, 20.0]\n",
      "2025/08/10 16:27:50 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 50.0\n",
      "2025/08/10 16:27:50 INFO dspy.teleprompt.mipro_optimizer_v2: =======================\n",
      "\n",
      "\n",
      "2025/08/10 16:27:50 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 5 / 9 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 0.13 / 1 (13.3%): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 4152.78it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/10 16:27:50 INFO dspy.evaluate.evaluate: Average Metric: 0.13333333333333336 / 1 (13.3%)\n",
      "2025/08/10 16:27:50 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 13.33 with parameters ['Predictor 0: Instruction 4'].\n",
      "2025/08/10 16:27:50 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [20.0, 33.33, 50.0, 20.0, 13.33]\n",
      "2025/08/10 16:27:50 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 50.0\n",
      "2025/08/10 16:27:50 INFO dspy.teleprompt.mipro_optimizer_v2: =======================\n",
      "\n",
      "\n",
      "2025/08/10 16:27:50 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 6 / 9 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 0.33 / 1 (33.3%): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 1223.54it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/10 16:27:50 INFO dspy.evaluate.evaluate: Average Metric: 0.3333333333333333 / 1 (33.3%)\n",
      "2025/08/10 16:27:50 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 33.33 with parameters ['Predictor 0: Instruction 2'].\n",
      "2025/08/10 16:27:50 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [20.0, 33.33, 50.0, 20.0, 13.33, 33.33]\n",
      "2025/08/10 16:27:50 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 50.0\n",
      "2025/08/10 16:27:50 INFO dspy.teleprompt.mipro_optimizer_v2: =======================\n",
      "\n",
      "\n",
      "2025/08/10 16:27:50 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 7 / 9 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 0.33 / 1 (33.3%): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 4084.04it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/10 16:27:50 INFO dspy.evaluate.evaluate: Average Metric: 0.3333333333333333 / 1 (33.3%)\n",
      "2025/08/10 16:27:50 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 33.33 with parameters ['Predictor 0: Instruction 2'].\n",
      "2025/08/10 16:27:50 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [20.0, 33.33, 50.0, 20.0, 13.33, 33.33, 33.33]\n",
      "2025/08/10 16:27:50 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 50.0\n",
      "2025/08/10 16:27:50 INFO dspy.teleprompt.mipro_optimizer_v2: =======================\n",
      "\n",
      "\n",
      "2025/08/10 16:27:50 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 8 / 9 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 0.20 / 1 (20.0%): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 4219.62it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/10 16:27:50 INFO dspy.evaluate.evaluate: Average Metric: 0.2 / 1 (20.0%)\n",
      "2025/08/10 16:27:50 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 20.0 with parameters ['Predictor 0: Instruction 0'].\n",
      "2025/08/10 16:27:50 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [20.0, 33.33, 50.0, 20.0, 13.33, 33.33, 33.33, 20.0]\n",
      "2025/08/10 16:27:50 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 50.0\n",
      "2025/08/10 16:27:50 INFO dspy.teleprompt.mipro_optimizer_v2: =======================\n",
      "\n",
      "\n",
      "2025/08/10 16:27:50 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 9 / 9 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 0.33 / 1 (33.3%): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 3498.17it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/10 16:27:50 INFO dspy.evaluate.evaluate: Average Metric: 0.3333333333333333 / 1 (33.3%)\n",
      "2025/08/10 16:27:50 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 33.33 with parameters ['Predictor 0: Instruction 2'].\n",
      "2025/08/10 16:27:50 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [20.0, 33.33, 50.0, 20.0, 13.33, 33.33, 33.33, 20.0, 33.33]\n",
      "2025/08/10 16:27:50 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 50.0\n",
      "2025/08/10 16:27:50 INFO dspy.teleprompt.mipro_optimizer_v2: =======================\n",
      "\n",
      "\n",
      "2025/08/10 16:27:50 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 10 / 9 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 0.20 / 1 (20.0%): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 3423.92it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/10 16:27:50 INFO dspy.evaluate.evaluate: Average Metric: 0.2 / 1 (20.0%)\n",
      "2025/08/10 16:27:50 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 20.0 with parameters ['Predictor 0: Instruction 0'].\n",
      "2025/08/10 16:27:50 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [20.0, 33.33, 50.0, 20.0, 13.33, 33.33, 33.33, 20.0, 33.33, 20.0]\n",
      "2025/08/10 16:27:50 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 50.0\n",
      "2025/08/10 16:27:50 INFO dspy.teleprompt.mipro_optimizer_v2: ========================\n",
      "\n",
      "\n",
      "2025/08/10 16:27:50 INFO dspy.teleprompt.mipro_optimizer_v2: Returning best identified program with score 50.0!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction(\n",
      "    generation='The capital of Germany is Berlin.'\n",
      ")\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[34m[2025-08-10T16:27:50.191634]\u001b[0m\n",
      "\n",
      "\u001b[31mSystem message:\u001b[0m\n",
      "\n",
      "Your input fields are:\n",
      "1. `prompt` (str):\n",
      "Your output fields are:\n",
      "1. `generation` (str):\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## prompt ## ]]\n",
      "{prompt}\n",
      "\n",
      "[[ ## generation ## ]]\n",
      "{generation}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "In adhering to this structure, your objective is: \n",
      "        You are a knowledgeable and concise general knowledge expert. Provide accurate, fact-based answers to straightforward questions in one or two sentences, ensuring clarity and precision.\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## prompt ## ]]\n",
      "What is the capital of Germany?\n",
      "\n",
      "Respond with the corresponding output fields, starting with the field `[[ ## generation ## ]]`, and then ending with the marker for `[[ ## completed ## ]]`.\n",
      "\n",
      "\n",
      "\u001b[31mResponse:\u001b[0m\n",
      "\n",
      "\u001b[32m[[ ## generation ## ]]\n",
      "The capital of Germany is Berlin.\n",
      "\n",
      "[[ ## completed ## ]]\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "optimizer = dspy.MIPROv2(concise_qna_metric, max_bootstrapped_demos=0, max_labeled_demos=0)\n",
    "my_program_optimized = optimizer.compile(my_program, trainset=trainset, requires_permission_to_run=False)\n",
    "print(my_program_optimized(prompt=\"What is the capital of Germany?\"))\n",
    "my_program_optimized.inspect_history()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35faed0",
   "metadata": {},
   "source": [
    "## 6) Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77bea211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base: 0.0909090909090909 Optimized: 0.08333333333333333\n"
     ]
    }
   ],
   "source": [
    "def evaluate(program, dataset, metric):\n",
    "    scores = []\n",
    "    for ex in dataset:\n",
    "        # pull input & reference safely from dspy.Example\n",
    "        user_prompt = getattr(ex, \"prompt\", None) or getattr(ex, \"inputs\", {}).get(\"prompt\", \"\")\n",
    "        ref_answer  = getattr(ex, \"generation\", None) or getattr(ex, \"outputs\", {}).get(\"generation\", \"\")\n",
    "\n",
    "        # run program\n",
    "        pred = program(prompt=user_prompt)\n",
    "\n",
    "        # normalize prediction to a dict with \"generation\"\n",
    "        gen = getattr(pred, \"generation\", None)\n",
    "        if gen is None and hasattr(pred, \"as_dict\"):\n",
    "            gen = pred.as_dict().get(\"generation\", \"\")\n",
    "        if gen is None and hasattr(pred, \"toDict\"):\n",
    "            gen = pred.toDict().get(\"generation\", \"\")\n",
    "        if gen is None and hasattr(pred, \"outputs\") and isinstance(pred.outputs, dict):\n",
    "            gen = pred.outputs.get(\"generation\", \"\")\n",
    "        if gen is None:\n",
    "            try:\n",
    "                gen = pred[\"generation\"]  # last resort if subscriptable\n",
    "            except Exception:\n",
    "                gen = str(pred)\n",
    "\n",
    "        ex_dict   = {\"prompt\": user_prompt, \"generation\": ref_answer}\n",
    "        pred_dict = {\"generation\": gen}\n",
    "        scores.append(metric(ex_dict, pred_dict))\n",
    "\n",
    "    return sum(scores) / len(scores) if scores else 0.0\n",
    "\n",
    "base = evaluate(my_program, devset, concise_qna_metric)\n",
    "opt  = evaluate(my_program_optimized, devset, concise_qna_metric)\n",
    "print(\"Base:\", base, \"Optimized:\", opt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6f5f4a",
   "metadata": {},
   "source": [
    "## 7) Export learned system prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8263f77e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a knowledgeable and concise general knowledge expert. Provide accurate, fact-based answers to straightforward questions in one or two sentences, ensuring clarity and precision.\n",
      "\n",
      "Saved to optimized_system_prompt.txt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "final_instructions = my_program_optimized.signature.instructions\n",
    "with open(\"optimized_system_prompt.txt\",\"w\",encoding=\"utf-8\") as f:\n",
    "    f.write(final_instructions)\n",
    "print(final_instructions)\n",
    "print(\"\\nSaved to optimized_system_prompt.txt\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
